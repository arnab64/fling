{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: classifying SPAM with fLing\n",
    "\n",
    "import matplotlib as mpl\n",
    "from imp import reload\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk,re,pprint\n",
    "import sys,glob,os\n",
    "import operator, string, argparse, math, random, statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ã¼ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "0         ham  Go until jurong point, crazy.. Available only ...\n",
       "1         ham                      Ok lar... Joking wif u oni...\n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         ham  U dun say so early hor... U c already then say...\n",
       "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...       ...                                                ...\n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568      ham              Will Ã¼ b going to esplanade fr home?\n",
       "5569      ham  Pity, * was in mood for that. So...any other s...\n",
       "5570      ham  The guy did some bitching but I acted like i'd...\n",
       "5571      ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fling import utilities as ut\n",
    "from fling import tfidfModule as tfm\n",
    "\n",
    "#load and preProcess (tokenize) the data, you can use other tokenizers as well\n",
    "os.chdir(\"/Users/arnabborah/Documents/repositories/fling/\")\n",
    "spamtm = tfm.dataProcessor(\"datasets/spamTextMessages.csv\",None)\n",
    "spamtm.dataInitial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ================================================== ] 100.00%\n",
      "Adding term frequency column based on stopsRemoved\n",
      "[ ================================================== ] 100.00%\n",
      "Computing list of words for IDF...\n",
      "\n",
      "Created list of terms for IDF matrix with 8780  terms.\n",
      "\n",
      "Computing global IDF matrix...\n",
      "\n",
      "[ ================================================== ] 100.00%\n",
      "Computing and adding TF-IDF column based on stopsRemoved\n",
      "[ ================================================== ] 100.00%"
     ]
    }
   ],
   "source": [
    "# creating a flingTFIDF to compute TF-IDF and add it as a new column (pd.dataframe) to data\n",
    "ftf = tfm.flingTFIDF(spamtm.dataInitial,'Message')\n",
    "ftf.smartTokenizeColumn()\n",
    "ftf.getTF()\n",
    "ftf.computeIDFmatrix()\n",
    "ftf.getTFIDF()\n",
    "\n",
    "#do the next line only if you are computing distances on tfIDF dict only\n",
    "ftf.createDistanceMetadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5572 documents added!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>stopsRemoved</th>\n",
       "      <th>tfMatrix</th>\n",
       "      <th>sumTFIDF</th>\n",
       "      <th>doc2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0          go   1 ...</td>\n",
       "      <td>38.281443</td>\n",
       "      <td>[0.015742207, 0.0031893118, 0.010138756, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0      ok   1  1.31950...</td>\n",
       "      <td>12.583182</td>\n",
       "      <td>[-0.014953367, 0.030154036, 0.017708715, -0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry  wkly comp win fa cup final tkts st...</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0         entry ...</td>\n",
       "      <td>49.524838</td>\n",
       "      <td>[0.008385706, 0.004221165, -2.3364251e-05, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0        u   2  1.669...</td>\n",
       "      <td>16.431526</td>\n",
       "      <td>[0.029679298, 0.06244122, -0.008049136, -0.119...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think goes usf lives around though</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0     nah   1  2.70461...</td>\n",
       "      <td>16.678825</td>\n",
       "      <td>[0.004876227, -0.008055425, 0.0023417333, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>nd time tried  contact u u â£ pound prize  cla...</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0            ...</td>\n",
       "      <td>29.685673</td>\n",
       "      <td>[0.043106798, 0.06623637, -0.010588597, -0.185...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ã¼ b going to esplanade fr home?</td>\n",
       "      <td>ã¼ b going esplanade fr home</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0         ã¼   1  1...</td>\n",
       "      <td>12.328684</td>\n",
       "      <td>[0.016016621, -0.01830655, 0.016508967, -0.105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity * mood soany suggestions</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0         pity   ...</td>\n",
       "      <td>15.080331</td>\n",
       "      <td>[-0.18763976, 0.03453686, -0.027078941, -0.055...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>guy bitching acted like i'd interested buying ...</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0          guy   ...</td>\n",
       "      <td>32.770129</td>\n",
       "      <td>[0.009096158, -0.0057535497, 0.004273705, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl true name</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0  rofl   1  3.143951\n",
       "1 ...</td>\n",
       "      <td>7.558242</td>\n",
       "      <td>[-0.0014662278, 0.009742865, 0.0015902708, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message  \\\n",
       "0         ham  Go until jurong point, crazy.. Available only ...   \n",
       "1         ham                      Ok lar... Joking wif u oni...   \n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3         ham  U dun say so early hor... U c already then say...   \n",
       "4         ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...       ...                                                ...   \n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568      ham              Will Ã¼ b going to esplanade fr home?   \n",
       "5569      ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570      ham  The guy did some bitching but I acted like i'd...   \n",
       "5571      ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                           stopsRemoved  \\\n",
       "0     go jurong point crazy available bugis n great ...   \n",
       "1                               ok lar joking wif u oni   \n",
       "2     free entry  wkly comp win fa cup final tkts st...   \n",
       "3                   u dun say early hor u c already say   \n",
       "4                nah think goes usf lives around though   \n",
       "...                                                 ...   \n",
       "5567  nd time tried  contact u u â£ pound prize  cla...   \n",
       "5568                       ã¼ b going esplanade fr home   \n",
       "5569                      pity * mood soany suggestions   \n",
       "5570  guy bitching acted like i'd interested buying ...   \n",
       "5571                                     rofl true name   \n",
       "\n",
       "                                               tfMatrix   sumTFIDF  \\\n",
       "0              word  tf    tf-idf\n",
       "0          go   1 ...  38.281443   \n",
       "1          word  tf    tf-idf\n",
       "0      ok   1  1.31950...  12.583182   \n",
       "2                word  tf    tf-idf\n",
       "0         entry ...  49.524838   \n",
       "3           word  tf    tf-idf\n",
       "0        u   2  1.669...  16.431526   \n",
       "4          word  tf    tf-idf\n",
       "0     nah   1  2.70461...  16.678825   \n",
       "...                                                 ...        ...   \n",
       "5567                word  tf    tf-idf\n",
       "0            ...  29.685673   \n",
       "5568          word  tf    tf-idf\n",
       "0         ã¼   1  1...  12.328684   \n",
       "5569            word  tf    tf-idf\n",
       "0         pity   ...  15.080331   \n",
       "5570            word  tf    tf-idf\n",
       "0          guy   ...  32.770129   \n",
       "5571     word  tf    tf-idf\n",
       "0  rofl   1  3.143951\n",
       "1 ...   7.558242   \n",
       "\n",
       "                                                doc2vec  \n",
       "0     [0.015742207, 0.0031893118, 0.010138756, -0.08...  \n",
       "1     [-0.014953367, 0.030154036, 0.017708715, -0.10...  \n",
       "2     [0.008385706, 0.004221165, -2.3364251e-05, -0....  \n",
       "3     [0.029679298, 0.06244122, -0.008049136, -0.119...  \n",
       "4     [0.004876227, -0.008055425, 0.0023417333, 0.00...  \n",
       "...                                                 ...  \n",
       "5567  [0.043106798, 0.06623637, -0.010588597, -0.185...  \n",
       "5568  [0.016016621, -0.01830655, 0.016508967, -0.105...  \n",
       "5569  [-0.18763976, 0.03453686, -0.027078941, -0.055...  \n",
       "5570  [0.009096158, -0.0057535497, 0.004273705, -0.0...  \n",
       "5571  [-0.0014662278, 0.009742865, 0.0015902708, -0....  \n",
       "\n",
       "[5572 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from fling import vectorize as vect\n",
    "\n",
    "# training and adding doc2vec vectors based on column 'Messages'.\n",
    "# gensim is a requirement to train doc2vec vectors \n",
    "vecc = vect.vectorize(ftf.data,'Message')\n",
    "trained_doc2vec_model = vecc.trainDocVectors()\n",
    "vecc.addDocVectors()\n",
    "vecc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Working on pretrained word embeddings!\n",
      "\n",
      "Loading Glove Model\n",
      "\n",
      "400000  words loaded!\n",
      "\n",
      "GloVe Vectors Loaded!\n",
      "\n",
      "[ ================================================== ] 100.00%\n",
      "Computing column: vec_tfidf-glove\n",
      "[ ==                                                 ] 5.81%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnabborah/Documents/repositories/fling/fling/flingPretrained.py:237: RuntimeWarning: Mean of empty slice\n",
      "  return(np.nanmean(docVecList,axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ =========================================          ] 83.44%%"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fling import flingPretrained as fpt\n",
    "\n",
    "# creating a flingPretrained\n",
    "# dataProcessed = pd.read_pickle('datasets/data_tfidf_processed.pkl')\n",
    "fdb = fpt.flingPretrained(vecc.data)\n",
    "#adding pretrained glove vectors \n",
    "fdb.loadPretrainedWordVectors('glove')\n",
    "fdb.addDocumentGloveVectors()\n",
    "\n",
    "# adding combo vectors with tfidf and (glove + doc2vec) for inter sentence semantic information addition\n",
    "fdb.tfidf2vec('tf-idf','glove')\n",
    "# fdb.tfidf2vec('tf-idf','doc2vec')\n",
    "fdb.splitTestTrain()\n",
    "fdb.dataTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing groupCharacteristics for, Category\n",
      "Characteristic of glove \n",
      " None\n",
      "Characteristic of vec_tfidf-doc2vec \n",
      " None\n",
      "Characteristic of vec_tfidf-glove \n",
      "                                             vec_tfidf-glove\n",
      "Category                                                   \n",
      "ham       [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
      "spam      [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
      "Characteristic of doc2vec \n",
      "                                                     doc2vec\n",
      "Category                                                   \n",
      "ham       [-0.0008339239, 0.008468696, 0.0014372141, -0....\n",
      "spam      [0.00509379, 0.008787291, -0.0049210927, -0.05...\n",
      "Characteristic of glove-vector \n",
      "                                                glove-vector\n",
      "Category                                                   \n",
      "ham       [0.08621057522946847, 0.16108873455431685, 0.1...\n",
      "spam      [0.038020029286601906, 0.25794960063990663, 0....\n",
      "Characteristic of glove-tfIDF \n",
      "                                                 glove-tfIDF\n",
      "Category                                                   \n",
      "ham       [0.08615151890437718, 0.16173257886936682, 0.1...\n",
      "spam      [0.032436123023218626, 0.24874980733559582, 0....\n"
     ]
    }
   ],
   "source": [
    "# train group characteristics on column 'category' \n",
    "fdb.createGroupedCharacteristics('Category')\n",
    "for key in fdb.groupedCharacteristic.keys():\n",
    "    print('Characteristic of',key,'\\n',fdb.groupedCharacteristic[key])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnabborah/Documents/repositories/fling/fling/flingPretrained.py:284: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.dataTest[groupName] = computedGroups\n"
     ]
    }
   ],
   "source": [
    "# predict vector based Category for each type of vector added\n",
    "fdb.addVectorComputedGroup('glove-vector','cGroup_glove')\n",
    "fdb.addVectorComputedGroup('doc2vec','cGroup_doc2vec')\n",
    "fdb.addVectorComputedGroup('glove-tfIDF','cGroup_gloveWt_tfidf')\n",
    "fdb.addVectorComputedGroup('vec_tfidf-glove','cGroup_tfidf-glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of cGroup_glove 79.84449760765551 %\n",
      "Accuracy of cGroup_doc2vec 78.88755980861244 %\n",
      "Accuracy of cGroup_gloveWt_tfidf 79.90430622009569 %\n",
      "Accuracy of cGroup_tfidf-glove 0.0 %\n"
     ]
    }
   ],
   "source": [
    "#fdb.addVectorComputedGroup('vec_tfidf-doc2vec','cGroup_tfidf-doc2vec')\n",
    "fdb.getAccuracy('Category','cGroup_glove')\n",
    "fdb.getAccuracy('Category','cGroup_doc2vec')\n",
    "fdb.getAccuracy('Category','cGroup_gloveWt_tfidf')\n",
    "fdb.getAccuracy('Category','cGroup_tfidf-glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
