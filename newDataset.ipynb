{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import nltk,re,pprint\n",
    "import sys,glob,os\n",
    "import operator, string, argparse, math\n",
    "\n",
    "# class to read and preprocess data\n",
    "class dataProcessor:\n",
    "    def __init__(self, fname, keepFactors):\n",
    "        #keep_factors = ['Job Description', 'Company Name', 'Industry']\n",
    "        self.dataInitial = pd.read_csv(fname, encoding=\"latin\")\n",
    "        if keepFactors:\n",
    "            self.dataInitialSmall = self.dataInitial[['Job Description', 'Company Name', 'Industry']]\n",
    "        else:\n",
    "            self.dataInitialSmall = None\n",
    "\n",
    "    # pipeline for purifying the text, write-pipeline, so just output filename can be provided\n",
    "    def rem_stop_punct(self,originalText, ofilename):\n",
    "        splittedText = originalText.split()\n",
    "        lenl = len(splittedText)\n",
    "        #print(\"Length is: \",lenl, splittedText[:5])\n",
    "        ofile = open(ofilename,'a')\n",
    "        \n",
    "        for r in range(lenl):\n",
    "            linex = splittedText[r]\n",
    "            linex2 = \"\".join(c for c in linex if c not in ('!','.',':',',','?',';','``','&','-','\"','(',')','[',']','0','1','2','3','4','5','6','7','8','9'))\n",
    "            linex3 = linex2.split()\n",
    "            #prog=(r+1)/len(rawlines)\n",
    "            for s in range(len(linex3)):\n",
    "                noword = linex3[s].lower()\n",
    "                if noword not in self.swords:\n",
    "                    ofile.write(noword)\n",
    "                    ofile.write(\" \")\n",
    "\n",
    "# primary tf-idf class\n",
    "class flingTFIDF:\n",
    "    def __init__(self,data,cname):\n",
    "        self.idfMatrix = {}\n",
    "        self.distanceMatrix = {}\n",
    "        self.termsforIDF = []\n",
    "        self.cname = cname\n",
    "        self.data = data\n",
    "        self.lenv = len(self.data)\n",
    "        self.swords = set(stopwords.words('english'))\n",
    "\n",
    "    def drawProgressBar(self,percent, barLen = 50):\t\t\t#just a progress bar so that you dont lose patience\n",
    "        sys.stdout.write(\"\\r\")\n",
    "        progress = \"\"\n",
    "        for i in range(barLen):\n",
    "            if i<int(barLen * percent):\n",
    "                progress += \"=\"\n",
    "            else:\n",
    "                progress += \" \"\n",
    "        sys.stdout.write(\"[ %s ] %.2f%%\" % (progress, percent * 100))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    def rem_stop_punct(self,originalText):\n",
    "        splittedText = originalText.split()\n",
    "        lenl = len(splittedText)\n",
    "        wordFiltered = []\n",
    "        tSent = []\n",
    "        for r in range(lenl):\n",
    "            wordx_1 = splittedText[r]\n",
    "            wordx_2 = \"\".join(c for c in wordx_1 if c not in ('!','.',':',',','?',';','``','&','-','\"','(',')','[',']','0','1','2','3','4','5','6','7','8','9')) \n",
    "            sWord = wordx_2.lower()\n",
    "            if sWord not in self.swords:\n",
    "                tSent.append(sWord)\n",
    "        return \" \".join(tSent)\n",
    "        \n",
    "    def smartTokenizeColumn(self):\n",
    "        self.stopsRemoved = []\n",
    "        for index, row in self.data.iterrows():\n",
    "            prog=(index+1)/self.lenv\n",
    "            originText = row[self.cname]\n",
    "            sentx = self.rem_stop_punct(originText)\n",
    "            self.drawProgressBar(prog)\n",
    "            self.data.loc[index,'stopsRemoved'] = sentx\n",
    "        self.cname = 'stopsRemoved'\n",
    "        \n",
    "    def getTF(self):\n",
    "        print(\"\\nAdding term frequency column based on\",self.cname)\n",
    "        tfMatrixList = []\n",
    "        for index, row in self.data.iterrows():\n",
    "            words_in_column = row[self.cname].split()\n",
    "            if len(words_in_column)!=0:\n",
    "                counts_all = Counter(words_in_column)\n",
    "                words, count_values = zip(*counts_all.items())\n",
    "                values_sorted, words_sorted = zip(*sorted(zip(count_values, words), key=operator.itemgetter(0), reverse=True))\n",
    "                tfMatrixList.append(pd.DataFrame({'word': words_sorted, 'tf': values_sorted}))\n",
    "                #self.data.loc[index,'tfMatrix'] = countdf\n",
    "            else:\n",
    "                #self.data.loc[index,'tfMatrix'] = pd.DataFrame(columns = ['word','tf'])\n",
    "                tfMatrixList.append(pd.DataFrame(columns = ['word','tf']))\n",
    "            prog=(index+1)/self.lenv\n",
    "            self.drawProgressBar(prog)\n",
    "        self.data['tfMatrix'] = tfMatrixList\n",
    "        \n",
    "    def getTFIDF(self):\n",
    "        print(\"\\nComputing and adding TF-IDF column based on\",self.cname)\n",
    "        for index, row in self.data.iterrows():\n",
    "            tfmatrixThisrow = row['tfMatrix']\n",
    "            tempTFIDF = []\n",
    "            for indx, rwx in tfmatrixThisrow.iterrows():\n",
    "                trmx = rwx['word']\n",
    "                tfx = rwx['tf']\n",
    "                idfx = self.idfMatrix[trmx]\n",
    "                tfidfx = tfx*idfx\n",
    "                tempTFIDF.append(tfidfx)\n",
    "                #tfmatrixThisrow.loc[index,'tf-idf'] = tfidfx\n",
    "            tfmatrixThisrow['tf-idf'] = tempTFIDF\n",
    "            #sumtfidf = tfmatrixThisrow['tf-idf'].sum() \n",
    "            prog=(index+1)/self.lenv\n",
    "            self.drawProgressBar(prog)\n",
    "                \n",
    "    def computeIDFlistofterms(self):\n",
    "        totalwords = 0\n",
    "        print(\"\\nComputing list of words for IDF...\\n\")\n",
    "        for index, row in self.data.iterrows():\n",
    "            words_in_column = set(row[self.cname].split())  \n",
    "            for word in words_in_column:\n",
    "                if word not in self.termsforIDF:\n",
    "                    self.termsforIDF.append(word)\n",
    "                    totalwords+=1\n",
    "        print(\"Created list of terms for IDF matrix with\", totalwords,\" terms.\")     \n",
    "        \n",
    "    def getIdf(self,term):\n",
    "        countPresentDocs = 0\n",
    "        lenidf = len(self.termsforIDF)\n",
    "        for i in range(lenidf):\n",
    "            tfx = self.getTermFreq(i,term)\n",
    "            if tfx>0:\n",
    "                countPresentDocs+=1\n",
    "            prog=(i+1)/lenidf\n",
    "            self.drawProgressBar(prog)\n",
    "        return countPresentDocs\n",
    "        \n",
    "    def computeIDFmatrix(self):\n",
    "        self.computeIDFlistofterms()\n",
    "        print(\"\\nComputing global IDF matrix...\\n\")\n",
    "        for term in self.termsforIDF:\n",
    "            self.idfMatrix[term]=0\n",
    "        for index, row in self.data.iterrows():\n",
    "            listofterms = list(self.data['tfMatrix'][index]['word'])\n",
    "            for term in listofterms:\n",
    "                self.idfMatrix[term]=self.idfMatrix[term]+1\n",
    "            prog=(index+1)/self.lenv\n",
    "            self.drawProgressBar(prog)\n",
    "        for term in self.termsforIDF:\n",
    "            idfx = self.idfMatrix[term]          \n",
    "            idfy = self.lenv/float(1+idfx)\n",
    "            idfz = math.log(idfy,10)\n",
    "            self.idfMatrix[term] = idfz\n",
    "            \n",
    "    def showData(self):\n",
    "        print(self.data['tfMatrix'])\n",
    "        \n",
    "    def createDistanceMetadata(self):\n",
    "        #sumList = []\n",
    "        for index, row in self.data.iterrows():\n",
    "            tfmatrixThisrow = row['tfMatrix']\n",
    "            sumTFIDF = tfmatrixThisrow['tf-idf'].sum()\n",
    "            #sumList.append({'sumTFIDF':sumTFIDF})\n",
    "            self.data.loc[index,'sumTFIDF'] = sumTFIDF\n",
    "            prog=(index+1)/self.lenv\n",
    "            self.drawProgressBar(prog)\n",
    "              \n",
    "    def distanceBtnTwoDocs(self, docId_1, docId_2):\n",
    "        listWords_1 = set(list(self.data['tfMatrix'][docId_1]['word']))\n",
    "        listWords_2 = set(list(self.data['tfMatrix'][docId_2]['word']))\n",
    "        common = listWords_1.intersection(listWords_2)\n",
    "        diff1_2 = listWords_1.difference(listWords_2)\n",
    "        diff2_1 = listWords_2.difference(listWords_1)\n",
    "        sumwt1 = self.data['sumTFIDF'][docId_1]\n",
    "        sumwt2 = self.data['sumTFIDF'][docId_2]\n",
    "        score_common, score_doc1, score_doc2 = 0,0,0\n",
    "        for word_c in common:\n",
    "            score_1 = float(self.data['tfMatrix'][docId_1].loc[self.data['tfMatrix'][docId_1]['word'] == word_c]['tf-idf'])\n",
    "            score_2 = float(self.data['tfMatrix'][docId_2].loc[self.data['tfMatrix'][docId_2]['word'] == word_c]['tf-idf'])\n",
    "            score_common += abs(score_1/float(sumwt1) - score_2/float(sumwt2))\n",
    "        for word_d12 in diff1_2:\n",
    "            score_1 = float(self.data['tfMatrix'][docId_1].loc[self.data['tfMatrix'][docId_1]['word'] == word_d12]['tf-idf'])\n",
    "            score_doc1 += score_1/float(sumwt1)\n",
    "        for word_d21 in diff2_1:\n",
    "            score_2 = float(self.data['tfMatrix'][docId_2].loc[self.data['tfMatrix'][docId_2]['word'] == word_d21]['tf-idf'])\n",
    "            score_doc2 += score_2/float(sumwt2)\n",
    "        score_total = score_common + score_doc1 + score_doc2\n",
    "        return(score_total)\n",
    "    \n",
    "    def computeDistanceBtnAllDocs(self):\n",
    "        for j in range(100):\n",
    "            for k in range(10):\n",
    "                numx = j*10+k\n",
    "                dist = self.distanceBtnTwoDocs(j,k)\n",
    "                self.distanceMatrix[(j,k)] = dist\n",
    "                prog=(numx+1)/1000\n",
    "                self.drawProgressBar(prog)\n",
    "                \n",
    "        print(self.distanceMatrix[:10])\n",
    "    \n",
    "    def writeToFile(self,fname):\n",
    "        self.data.to_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from imp import reload\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk,re,pprint\n",
    "import sys,glob,os\n",
    "import operator, string, argparse, math, random, statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "class flingPretrained:\n",
    "    '''\n",
    "    Trains linguistic models: doc2vec, fastText, word2vec, SDAE\n",
    "    Load pretrained linguistic models: doc2vec, fastText, word2vec, SDAE\n",
    "    Save group characteristics\n",
    "    '''\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.nDocs = len(self.data)\n",
    "        self.nDocsTest = 0\n",
    "        self.allDistances = {}\n",
    "        self.groupedCharacteristic = {'glove' : None, 'vec_tfidf-doc2vec' : None, 'vec_tfidf-glove' : None, 'doc2vec' : None}\n",
    "        self.wordVecModel = {'glove':None, 'doc2vec':None}\n",
    "        print(\"\\nDBSCAN initialized!\\n\")\n",
    "        \n",
    "    def loadPretrainedWordVectors(self,vecType):\n",
    "        if vecType == 'glove':\n",
    "            self.wordVecModel['glove'] = self.loadGloveModel()\n",
    "            print(\"GloVe Vectors Loaded!\\n\") \n",
    "\n",
    "    def loadGloveModel(self):\n",
    "        print(\"Loading Glove Model\\n\")\n",
    "        try:\n",
    "            f = open('../datasets/glove.6B/glove.6B.50d.txt','r')\n",
    "        except:\n",
    "            f = open('datasets/glove.6B/glove.6B.50d.txt','r')\n",
    "        gloveModel = {}\n",
    "        for line in f:\n",
    "            splitLines = line.split()\n",
    "            word = splitLines[0]\n",
    "            wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n",
    "            gloveModel[word] = wordEmbedding\n",
    "        print(len(gloveModel),\" words loaded!\\n\")\n",
    "        return(gloveModel)\n",
    "    \n",
    "    '''\n",
    "    Returns the computed GloVe vector for the document. Note: a document contains multiple words, \n",
    "    and we have word vectors corresponding to every word in Glove\n",
    "    '''\n",
    "    def getDocVector(self,doc_Id):\n",
    "        gvl=self.getGloveVectorList(listx)\n",
    "        glove_dv = np.mean(gvl,axis=0)\n",
    "        return(glove_dv)\n",
    "    \n",
    "    '''\n",
    "    Add the new computed GloVe vector on the document to the data.\n",
    "    '''\n",
    "    def addDocumentGloveVector(self):\n",
    "        vecL = []\n",
    "        for indx in range(self.nDocs):\n",
    "            listWords_1 = set(list(self.data['tfMatrix'][int(indx)]['word']))\n",
    "            gvl=self.getGloveVectorList(listWords_1)\n",
    "            vecL.append(np.mean(gvl,axis=0))\n",
    "        self.data['glove-vector'] = vecL\n",
    "\n",
    "    '''\n",
    "    Distance between two documents using TF-IDF dictionaries.\n",
    "        Method used: Using 'percentage of importance' by using tf-idf score as weights\n",
    "    '''\n",
    "    def distanceBtnTwoDocs(self, docId_1, docId_2):\n",
    "        listWords_1 = set(list(self.data['tfMatrix'][int(docId_1)]['word']))\n",
    "        listWords_2 = set(list(self.data['tfMatrix'][int(docId_2)]['word']))\n",
    "        common = listWords_1.intersection(listWords_2)\n",
    "        diff1_2 = listWords_1.difference(listWords_2)\n",
    "        diff2_1 = listWords_2.difference(listWords_1)\n",
    "        sumwt1 = self.data['sumTFIDF'][docId_1]\n",
    "        sumwt2 = self.data['sumTFIDF'][docId_2]\n",
    "        score_common, score_doc1, score_doc2 = 0,0,0\n",
    "        #print(len(common),len(diff1_2),len(diff2_1))\n",
    "        for word_c in common:\n",
    "            score_1 = float(self.data['tfMatrix'][docId_1].loc[self.data['tfMatrix'][docId_1]['word'] == word_c]['tf-idf'])\n",
    "            score_2 = float(self.data['tfMatrix'][docId_2].loc[self.data['tfMatrix'][docId_2]['word'] == word_c]['tf-idf'])\n",
    "            score_common += abs(score_1/float(sumwt1) - score_2/float(sumwt2))\n",
    "        for word_d12 in diff1_2:\n",
    "            score_1 = float(self.data['tfMatrix'][docId_1].loc[self.data['tfMatrix'][docId_1]['word'] == word_d12]['tf-idf'])\n",
    "            score_doc1 += score_1/float(sumwt1)\n",
    "        for word_d21 in diff2_1:\n",
    "            score_2 = float(self.data['tfMatrix'][docId_2].loc[self.data['tfMatrix'][docId_2]['word'] == word_d21]['tf-idf'])\n",
    "            score_doc2 += score_2/float(sumwt2)\n",
    "        score_total = score_common + score_doc1 + score_doc2\n",
    "        return(score_total)\n",
    "    \n",
    "    '''\n",
    "    Returns a list of GloVe vectors for all words in the document.\n",
    "    '''\n",
    "    def getGloveVectorList(self,listx):\n",
    "        vecList = []\n",
    "        nf = []\n",
    "        for w in listx:\n",
    "            try:\n",
    "                vecList.append(self.wordVecModel['glove'][w])\n",
    "            except:\n",
    "                nf.append(w)\n",
    "                continue        \n",
    "        if len(vecList)==0:\n",
    "            return([[0]*50])\n",
    "        vecArray = np.stack(vecList, axis=0)\n",
    "        return vecArray\n",
    "    \n",
    "    #document vector is the average of all the word vectors gloVe\n",
    "    def getDocVector(self,listx):\n",
    "        gvl=self.getGloveVectorList(listx)\n",
    "        glove_dv = np.mean(gvl,axis=0)\n",
    "        return(glove_dv)\n",
    "    \n",
    "    '''\n",
    "    Returns the distance between two GloVe vectors.\n",
    "    '''\n",
    "    def getGloveDistance(self,docId_1,docId_2,method):\n",
    "        listWords_1 = set(list(self.data['tfMatrix'].iloc[int(docId_1)]['word']))\n",
    "        listWords_2 = set(list(self.data['tfMatrix'].iloc[int(docId_2)]['word']))\n",
    "        if method == 'average':\n",
    "            dv_1 = self.getDocVector(listWords_1)\n",
    "            dv_2 = self.getDocVector(listWords_2)\n",
    "            dist = np.linalg.norm(dv_1-dv_2)\n",
    "            return dist\n",
    "              \n",
    "    def drawProgressBar(self, percent, barLen = 50):\t\t\t#just a progress bar so that you dont lose patience\n",
    "        sys.stdout.write(\"\\r\")\n",
    "        progress = \"\"\n",
    "        for i in range(barLen):\n",
    "            if i<int(barLen * percent):\n",
    "                progress += \"=\"\n",
    "            else:\n",
    "                progress += \" \"\n",
    "        sys.stdout.write(\"[ %s ] %.2f%%\" % (progress, percent * 100))\n",
    "        sys.stdout.flush()\t\n",
    "\n",
    "    '''\n",
    "    sample distance between numx random documents and generate a bucketized histogram plot to get a better\n",
    "    idea of the inter-document distance in the data.\n",
    "    '''\n",
    "    def getDistanceDistribution(self,numx,method):\n",
    "        numHalf = int(numx/2)\n",
    "        doca,docb = [],[]\n",
    "        for i in range(numHalf):\n",
    "            doca.append(random.randint(1,1026))\n",
    "            docb.append(random.randint(1027,2053))\n",
    "        distanceSample = []\n",
    "        total = numHalf*numHalf\n",
    "        for doc_1 in range(len(doca)):\n",
    "            for doc_2 in range(len(docb)):\n",
    "                if method == 'glove':\n",
    "                    distanceSample.append(self.getGloveDistance(doca[doc_1],docb[doc_2],'average'))\n",
    "                else:\n",
    "                    distanceSample.append(self.getGloveDistance(doca[doc_1],docb[doc_2],'average'))\n",
    "                cov = doc_1*numHalf + doc_2\n",
    "                prog=(cov+1)/total\n",
    "                self.drawProgressBar(prog)\n",
    "        pltx = plot.hist(distanceSample,bins=20)\n",
    "        return(pltx)\n",
    "    \n",
    "    '''\n",
    "    Returns the gloVe vector for the word from the pre-trained gloVe vectors.\n",
    "    '''\n",
    "    def getGloveScore(self,w):\n",
    "        try:\n",
    "            return(self.wordVecModel['glove'][w])\n",
    "        except:\n",
    "            return([0*50]) \n",
    "    \n",
    "    '''\n",
    "    Combines document tfIDF dictionary with other document vectors to create combined vectors. \n",
    "    '''\n",
    "    def doctfidf2vec(self,docId,mode):\n",
    "        docVecList = []\n",
    "        listWords = list(self.data['tfMatrix'][int(docId)]['word'])\n",
    "        if mode == \"tf-only\":\n",
    "            scores = list(self.data['tfMatrix'][int(docId)]['tf'])\n",
    "        elif mode == \"tf-idf\":\n",
    "            scores = list(self.data['tfMatrix'][int(docId)]['tf-idf'])\n",
    "        lenW =len(listWords)\n",
    "        gloveScores = [self.getGloveScore(el) for el in listWords]\n",
    "        for j in range(lenW):\n",
    "            temp = [float(scores[j])]*50\n",
    "            #gloveScores[j]\n",
    "            res = [a*b for (a,b) in zip(temp,gloveScores[j])]\n",
    "            if len(res)==1:\n",
    "                continue;\n",
    "            else:\n",
    "                docVecList.append(res)            \n",
    "        return(np.mean(docVecList,axis=0))\n",
    "    \n",
    "    '''\n",
    "    For each group in the specified column, average all the document vectors in the \n",
    "    group to create a group characteristic\n",
    "    \n",
    "    TASK: explore more options of averaging the vectors. '''\n",
    "    def createGroupedCharacteristics(self,column):\n",
    "        self.dataTrain.groupby([column])\n",
    "        print(\"\\nComputing groupCharacteristics for GloVe!\")\n",
    "        self.groupedCharacteristic['glove-vector'] = self.dataTrain.groupby([column])['glove-vector'].apply(np.average).to_frame()\n",
    "        print(\"\\nComputing groupCharacteristics for doc2vec!\")\n",
    "        self.groupedCharacteristic['doc2vec'] = self.dataTrain.groupby([column])['doc2vec'].apply(np.average).to_frame()\n",
    "        #print(\"\\nComputing groupCharacteristics for tfidf-doc2vec!\")\n",
    "        #self.groupedCharacteristic['vec_tfidf-doc2vec'] = self.dataTrain.groupby([column])['vec_tfidf-doc2vec'].apply(np.average).to_frame()\n",
    "        print(\"\\nComputing groupCharacteristics for tfidf-GloVe!\")\n",
    "        self.groupedCharacteristic['vec_tfidf-glove'] = self.dataTrain.groupby([column])['vec_tfidf-glove'].apply(np.average).to_frame()\n",
    "       \n",
    "    '''\n",
    "    Function to return the group most simimar to the vector, based on distance computed with every group characteristics.\n",
    "    '''\n",
    "    def getNearestGroup(self,vec,vectorName):\n",
    "        minDist = math.inf\n",
    "        minGroup = None\n",
    "        for colx in fdb.groupedCharacteristic[vectorName].index.values:\n",
    "            vecy = fdb.groupedCharacteristic[vectorName].loc[colx].to_numpy(dtype=object)\n",
    "            #distx = np.linalg.norm(vec-vecy)\n",
    "            if np.sum(vec)!=0:\n",
    "                distx = np.linalg.norm(scipy.spatial.distance.euclidean(vec,vecy))\n",
    "                #print(\"case#1/distx\",distx)\n",
    "            else:\n",
    "                distx = np.linalg.norm(vecy.dot(vecy))\n",
    "                #print(\"case#2/distx\",distx)\n",
    "            mag = np.sqrt(distx)\n",
    "            if mag<minDist:\n",
    "                minDist = distx\n",
    "                minGroup = colx                 \n",
    "        return minGroup\n",
    "    \n",
    "    '''\n",
    "    Explore options to optimize space using function.\n",
    "    '''\n",
    "    def splitTestTrain(self):\n",
    "        mPt = int(self.nDocs*0.7)\n",
    "        self.dataTrain = self.data[:mPt]\n",
    "        self.dataTest = self.data[mPt:]\n",
    "        self.nDocsTest = len(self.dataTest)\n",
    "               \n",
    "    '''\n",
    "    Add computed group as a new column.\n",
    "    '''\n",
    "    def addVectorComputedGroup(self,vectorName,groupName):\n",
    "        computedGroups = []\n",
    "        for docId in range(self.nDocsTest):\n",
    "            computedGroup = self.getNearestGroup(self.dataTest[vectorName].iloc[docId],vectorName)\n",
    "            computedGroups.append(computedGroup)           \n",
    "        self.dataTest[groupName] = computedGroups      \n",
    "    '''\n",
    "    Simple percentage count of documents which got the correct labels assigned.\n",
    "    '''  \n",
    "    def getAccuracy(self,compareWith,vecName):\n",
    "        countCorrect = 0\n",
    "        for d in range(self.nDocsTest):\n",
    "            if self.dataTest[vecName].iloc[d] == self.dataTest[compareWith].iloc[d]:\n",
    "                countCorrect+=1\n",
    "        print(\"Accuracy of\",vecName,countCorrect/self.nDocsTest*100,\"%\")\n",
    "            \n",
    "    '''\n",
    "    Convert tfIDF dictionary for every document with precomputed word-embeddings\n",
    "    '''\n",
    "    def tfidf2vec(self,mode,method):\n",
    "        vecL = []\n",
    "        if mode == 'tf-only':\n",
    "            columnName = 'vec_tf-' + method\n",
    "            print(\"\\nComputing column:\",columnName)\n",
    "            for indx in range(self.nDocs):\n",
    "                gvl=self.doctfidf2vec(indx,'tf-only')\n",
    "                vecL.append(gvl)\n",
    "                prog=(indx+1)/self.nDocs\n",
    "                self.drawProgressBar(prog)\n",
    "        else:\n",
    "            columnName = 'vec_tfidf-' + method\n",
    "            print(\"\\nComputing column:\",columnName)\n",
    "            for indx in range(self.nDocs):\n",
    "                gvl=self.doctfidf2vec(indx,'tf-idf')\n",
    "                vecL.append(gvl)\n",
    "                prog=(indx+1)/self.nDocs\n",
    "                self.drawProgressBar(prog)\n",
    "        self.data[columnName] = vecL\n",
    "\n",
    "class vectorize:\n",
    "    def __init__(self,data,factorName):\n",
    "        self.data = data\n",
    "        self.dataNew = []\n",
    "        self.model = None\n",
    "        self.swords = set(stopwords.words('english'))\n",
    "        self.factorName = factorName\n",
    "        for docId in range(len(self.data)):\n",
    "            dv_1 = self.data[factorName][int(docId)]\n",
    "            self.dataNew.append(dv_1)\n",
    "        self.nDocs = len(self.dataNew)\n",
    "        print(self.nDocs,\"documents added!\")\n",
    "        \n",
    "    '''\n",
    "    Tokenizer: Remove stopwords and punctuations.\n",
    "    TASK: Add standard available tokenizers.\n",
    "    '''\n",
    "    def rem_stop_punct(self,originalText):\n",
    "        splittedText = originalText.split()\n",
    "        lenl = len(splittedText)\n",
    "        wordFiltered = []\n",
    "        tSent = []\n",
    "        for r in range(lenl):\n",
    "            wordx_1 = splittedText[r]\n",
    "            wordx_2 = \"\".join(c for c in wordx_1 if c not in ('!','.',':',',','?',';','``','&','-','\"','(',')','[',']','0','1','2','3','4','5','6','7','8','9')) \n",
    "            sWord = wordx_2.lower()\n",
    "            if sWord not in self.swords:\n",
    "                tSent.append(sWord)\n",
    "        return tSent\n",
    "\n",
    "    def tagged_document(self,list_of_list_of_words):\n",
    "        for i, list_of_words in enumerate(list_of_list_of_words):\n",
    "            yield gensim.models.doc2vec.TaggedDocument(list_of_words, [i])\n",
    "\n",
    "    '''\n",
    "    Train doc2vec vectors on the training dataset.\n",
    "    '''\n",
    "    def trainDocVectors(self):\n",
    "        print(\"\\nTraining doc2vec model.\")\n",
    "        self.data_for_training = list(self.tagged_document(self.dataNew))\n",
    "        self.model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=30)\n",
    "        self.model.build_vocab(self.data_for_training)\n",
    "        self.model.train(self.data_for_training, total_examples=self.model.corpus_count, epochs=self.model.epochs)\n",
    "        #self.model.to_pickle(\"model_doc2vec.pkl\")\n",
    "        return(self.model)\n",
    "        \n",
    "    def addDocVectors(self):\n",
    "        print(\"\\nAdding doc2vec vectors to dataset.\")\n",
    "        docVectors = []\n",
    "        for docId in range(len(self.data)):\n",
    "            docVectors.append(self.model.infer_vector(self.rem_stop_punct(self.data[self.factorName][int(docId)])))\n",
    "        self.data['doc2vec'] = docVectors\n",
    "        \n",
    "class flingDBSCAN:\n",
    "    def __init__(self,data,epsilon,minPts,method):\n",
    "        self.data = data\n",
    "        self.method = method\n",
    "        self.minPts = minPts\n",
    "        self.noisePts = []\n",
    "        self.nDocs = len(self.data)\n",
    "        self.clusterCharacteristic = None \n",
    "        self.clusterIndex = 0 \n",
    "        self.clusterCount = 0 \n",
    "        self.clusterLabel = \"computedCluster\"\n",
    "        print(\"\\nflingDBSCAN initialized!\\n\")\n",
    "        self.clusterMetadata = {}\n",
    "        for i in range(self.nDocs):\n",
    "            self.clusterMetadata[i] = None\n",
    "        if epsilon:\n",
    "            self.epsilon = epsilon\n",
    "        else:\n",
    "            if method == 'glove':\n",
    "                self.epsilon = self.getBestDistance('glove')\n",
    "                print(\"\\nBest epsilon computed on GLOVE =\",self.epsilon,\"\\n\")\n",
    "            else:\n",
    "                self.epsilon = self.getBestDistance('tfidf')\n",
    "                print(\"\\nBest epsilon computed on GLOVE-TFIDF =\",self.epsilon,\"\\n\")\n",
    "            \n",
    "    def getBestDistance(self,method):\n",
    "        numx = 100\n",
    "        numHalf = int(numx/2)\n",
    "        doca,docb = [],[]\n",
    "        print(\"computing best distance\")\n",
    "        for i in range(numHalf):\n",
    "            doca.append(random.randint(1,int(self.nDocs/2)))\n",
    "            docb.append(random.randint(int(self.nDocs/2)+1,self.nDocs))\n",
    "        distanceSample = []\n",
    "        total = numHalf*numHalf\n",
    "        for doc_1 in range(len(doca)):\n",
    "            for doc_2 in range(len(docb)):\n",
    "                if method == 'glove':\n",
    "                    distanceSample.append(self.getDistance(doc_1,doc_2,'glove'))\n",
    "                else:\n",
    "                    distanceSample.append(self.getDistance(doc_1,doc_2,'tfidf'))\n",
    "                cov = doc_1*numHalf + doc_2\n",
    "                prog=(cov+1)/total\n",
    "                self.drawProgressBar(prog)\n",
    "        plt.show(plt.hist(distanceSample,bins=20))\n",
    "        return statistics.mean(distanceSample)\n",
    "            \n",
    "    def assignLabel(self,dictDist,label):\n",
    "        for el in dictDist:\n",
    "            self.clusterMetadata[el]=label\n",
    "            \n",
    "    def printClusterInfo(self):\n",
    "        print(\"Cluster characteristics:\")\n",
    "        print(\" -- vectors:\",self.method)\n",
    "        print(\" -- minPts:\",self.minPts)\n",
    "        print(\" -- EstimatedBestDistance\",self.epsilon)\n",
    "        print(\" --\",self.clusterCount,\"clusters formed!\")\n",
    "        print(\" --\",self.nDocs-len(self.noisePts),\"points assigned to clusters!\") \n",
    "        print(\" --\",len(self.noisePts),\"noise points!\\n\")\n",
    "        noisePc = len(self.noisePts)/self.nDocs*100\n",
    "        print(\" --\",noisePc,\"% noise!\\n\")\n",
    "            \n",
    "    def printClusterMetadata(self,n):\n",
    "        for j in range(n):\n",
    "            print(j, self.clusterMetadata[j])\n",
    "         \n",
    "    # range query equivalent function\n",
    "    def findNeighborOf(self,ptIndex,method):\n",
    "        distance = {}      \n",
    "        #first vector\n",
    "        if method == 'glove':\n",
    "            dv_1 = self.data['glove-vector'][int(ptIndex)] \n",
    "        elif method == 'tfidf':\n",
    "            dv_1 = self.data['tfidf2vec-tfidf'][int(ptIndex)]\n",
    "        \n",
    "        #iterating over the whole data for the second vector \n",
    "        if method == 'tfidf':\n",
    "            for j in range(self.nDocs):\n",
    "                dv_2 = self.data['tfidf2vec-tfidf'][j]\n",
    "                if j!=ptIndex:\n",
    "                    distx = self.getDistance(ptIndex,j,'tfidf')\n",
    "                    distance[j] = distx\n",
    "        elif method == 'glove':\n",
    "            for j in range(self.nDocs):\n",
    "                dv_2 = self.data['glove-vector'][j]\n",
    "                if j!=ptIndex:\n",
    "                    distx = self.getDistance(ptIndex,j,'glove')\n",
    "                    distance[j] = distx\n",
    "        \n",
    "        # keeping only elements at a distnce of less than epsilon\n",
    "        tempDistances = {key:value for (key,value) in distance.items() if value<self.epsilon}\n",
    "        newDistances = {key:value for (key,value) in tempDistances.items() if self.clusterMetadata[key]==None}\n",
    "        # keeping the cluster only if we \n",
    "        if len(newDistances)>self.minPts:    \n",
    "            return newDistances.keys()\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    def dbscanCompute(self):\n",
    "        print(\"\\ninitiating DBSCAN Clustering with\",self.method,\"vectors\\n\")\n",
    "        self.clusterMetadata[0]='cluster_0_'\n",
    "        for k in range(self.nDocs):\n",
    "            if not self.clusterMetadata[k]:\n",
    "                if self.method=='glove':\n",
    "                    neighbors = self.findNeighborOf(k,'glove')\n",
    "                else:\n",
    "                    neighbors = self.findNeighborOf(k,'tfidf')\n",
    "                if neighbors:\n",
    "                    self.clusterCount+=1\n",
    "                    clusterName = \"cluster_\" + str(self.clusterCount)+\"_\"\n",
    "                    self.clusterMetadata[k] = clusterName\n",
    "                    \n",
    "                    # neighboring points of original point\n",
    "                    for nbPoint in neighbors:\n",
    "                        if not self.clusterMetadata[nbPoint]:\n",
    "                            self.clusterMetadata[nbPoint] = clusterName\n",
    "                    if self.method=='glove':\n",
    "                        innerNeighbors = self.findNeighborOf(k,'glove')\n",
    "                    else:\n",
    "                        innerNeighbors = self.findNeighborOf(k,'tfidf')\n",
    "                    if innerNeighbors:\n",
    "                        for nb in innerNeighbors:\n",
    "                            self.clusterMetadata[nb] = clusterName\n",
    "                            neighbors.append(nb)                          \n",
    "                    print(\"\\n ---- \",clusterName,\"assigned to\",len(neighbors),\"points! ----\")\n",
    "                else:\n",
    "                    self.noisePts.append(k)\n",
    "            prog=(k+1)/self.nDocs\n",
    "            self.drawProgressBar(prog)\n",
    "        print(\"\\n\",self.clusterCount,\"clusters formed!\")\n",
    "\n",
    "    ''' get distance between two vectors based on method. Only single vector methods available. Combined methods yet to add.\n",
    "    '''\n",
    "    def getDistance(self,docId_1,docId_2,method):\n",
    "        if method == 'glove':\n",
    "            dv_1 = self.data['glove-vector'][int(docId_1)]\n",
    "            dv_2 = self.data['glove-vector'][int(docId_2)]\n",
    "        elif method == 'tfidf':\n",
    "            dv_1 = self.data['tfidf2vec-tfidf'][int(docId_1)]\n",
    "            dv_2 = self.data['tfidf2vec-tfidf'][int(docId_2)]           \n",
    "        dist = np.linalg.norm(dv_1-dv_2)\n",
    "        return dist\n",
    "    \n",
    "    def addClusterLabel(self,label):\n",
    "        self.clusterLabel = label\n",
    "        vec = []\n",
    "        for el in self.clusterMetadata.keys():\n",
    "            vec.append(self.clusterMetadata[el])\n",
    "        self.data[label] = vec\n",
    "        \n",
    "    def getNearestGroup(self,vec):\n",
    "        minDist = 100\n",
    "        minGroup = None\n",
    "        for colx in fdb.groupedCharacteristic.columns:\n",
    "            vecy = fdb.groupedCharacteristic[colx]['glove-vector']\n",
    "            distx = np.linalg.norm(vec-vecy)\n",
    "            if distx<minDist:\n",
    "                minDist = distx\n",
    "                minGroup = colx\n",
    "        return minGroup\n",
    "    \n",
    "    def addClusterMajorityLabel(self):\n",
    "        clusterMap = {}\n",
    "        for docId in range(self.nDocs):\n",
    "            computedGroup = self.getNearestGroup(self.data['glove-vector'][int(docId)])\n",
    "            clID = self.data['glove-vector'][int(docId)]\n",
    "            if clID not in self.clusterCharacteristic:\n",
    "                self.clusterCharacteristic[clID]=[computedGroup]\n",
    "            else:\n",
    "                self.clusterCharacteristic[clID].append(computedGroup)\n",
    "            prog=(docId+1)/self.nDocs\n",
    "            self.drawProgressBar(prog)\n",
    "        for k in self.clusterCharacteristic.key():\n",
    "            res = statistics.mode(self.clusterCharacteristic[k])\n",
    "            clusterMap[k] = res\n",
    "        return(clusterMap)\n",
    "\n",
    "    def addVectorComputedGroup(self,vecName,factorName):\n",
    "        computedGroups = []\n",
    "        for docId in range(self.nDocs):\n",
    "            computedGroup = self.getNearestGroup(self.data[vecName][int(docId)])\n",
    "            computedGroups.append(computedGroup)\n",
    "        self.data[factorName] = computedGroups\n",
    "              \n",
    "    def getAccuracy(self,compareWith):\n",
    "        countCorrect = 0\n",
    "        for d in range(self.nDocs):\n",
    "            if self.data['characteristicGroup'][d] == self.data[compareWith][d]:\n",
    "                countCorrect+=1\n",
    "        print(\"Accuracy:\",countCorrect/self.nDocs*100,\"%\")\n",
    "        \n",
    "    def evaluateClusterPerformance(self,compareWith):\n",
    "        return(metrics.adjusted_rand_score(self.data['characteristicGroup'],self.data[compareWith]))\n",
    "    \n",
    "    '''\n",
    "    TASK: optimize the progressbar.\n",
    "    '''\n",
    "    def drawProgressBar(self, percent, barLen = 50):\t\t\t#just a progress bar so that you dont lose patience\n",
    "        sys.stdout.write(\"\\r\")\n",
    "        progress = \"\"\n",
    "        for i in range(barLen):\n",
    "            if i<int(barLen * percent):\n",
    "                progress += \"=\"\n",
    "            else:\n",
    "                progress += \" \"\n",
    "        sys.stdout.write(\"[ %s ] %.2f%%\" % (progress, percent * 100))\n",
    "        sys.stdout.flush()\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'glove': None,\n",
       " 'vec_tfidf-doc2vec': None,\n",
       " 'vec_tfidf-glove': None,\n",
       " 'doc2vec': None}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in fdb.groupedCharacteristic.keys():\n",
    "    print(fdb.groupedCharacteristic[key])\n",
    "    \n",
    "fdb.groupedCharacteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fling import utilities as ut\n",
    "#from fling import tfidfModule as tfm\n",
    "os.chdir(\"/Users/arnabborah/Documents/repositories/fling/\")\n",
    "spamtm = dataProcessor(\"datasets/spamTextMessages.csv\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primary distance module run\n",
    "ftf = flingTFIDF(spamtm.dataInitial,'Message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ================================================== ] 100.00%\n",
      "Adding term frequency column based on stopsRemoved\n",
      "[ ================================================== ] 100.00%\n",
      "Computing list of words for IDF...\n",
      "\n",
      "Created list of terms for IDF matrix with 8780  terms.\n",
      "\n",
      "Computing global IDF matrix...\n",
      "\n",
      "[ ================================================== ] 100.00%\n",
      "Computing and adding TF-IDF column based on stopsRemoved\n",
      "[ ================================================== ] 100.00%"
     ]
    }
   ],
   "source": [
    "ftf.smartTokenizeColumn()\n",
    "ftf.getTF()\n",
    "ftf.computeIDFmatrix()\n",
    "ftf.getTFIDF()\n",
    "ftf.createDistanceMetadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DBSCAN initialized!\n",
      "\n",
      "Loading Glove Model\n",
      "\n",
      "400000  words loaded!\n",
      "\n",
      "GloVe Vectors Loaded!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FRESH START\n",
    "import gensim\n",
    "\n",
    "#dataProcessed = pd.read_pickle('datasets/data_tfidf_processed.pkl')\n",
    "fdb = flingPretrained(ftf.data)\n",
    "\n",
    "#adding pretrained glove vectors \n",
    "fdb.loadPretrainedWordVectors('glove')\n",
    "fdb.addDocumentGloveVector()\n",
    "\n",
    "#traininf and adding doc2vec vectors\n",
    "vecc = vectorize(fdb.data,'Message')\n",
    "fdb.wordVecModel['doc2vec'] = vecc.trainDocVectors()\n",
    "vecc.addDocVectors()\n",
    "\n",
    "#adding combo vectors with tfidf and (glove + doc2vec) for inter sentence semantic information addition\n",
    "fdb.tfidf2vec('tf-idf','glove')\n",
    "#fdb.tfidf2vec('tf-idf','doc2vec')\n",
    "fdb.splitTestTrain()\n",
    "\n",
    "# train group characteristics on column 'category' and predict vector based category, and compute error\n",
    "fdb.createGroupedCharacteristics('Category')\n",
    "fdb.addVectorComputedGroup('glove-vector','cGroup_glove')\n",
    "fdb.addVectorComputedGroup('doc2vec','cGroup_doc2vec')\n",
    "fdb.addVectorComputedGroup('vec_tfidf-glove','cGroup_tfidf-glove')\n",
    "#fdb.addVectorComputedGroup('vec_tfidf-doc2vec','cGroup_tfidf-doc2vec')\n",
    "fdb.getAccuracy('Category','cGroup_glove')\n",
    "fdb.getAccuracy('Category','cGroup_doc2vec')\n",
    "fdb.getAccuracy('Category','cGroup_tfidf-glove')\n",
    "#fdb.getAccuracy('Category','cGroup_tfidf-doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>stopsRemoved</th>\n",
       "      <th>tfMatrix</th>\n",
       "      <th>sumTFIDF</th>\n",
       "      <th>glove-vector</th>\n",
       "      <th>doc2vec</th>\n",
       "      <th>vec_tfidf-glove</th>\n",
       "      <th>cGroup_glove</th>\n",
       "      <th>cGroup_doc2vec</th>\n",
       "      <th>cGroup_tfidf-glove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ã mean it's confirmed... I tot they juz say o...</td>\n",
       "      <td>ã mean confirmed tot juz say oni ok</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0         ã   1  2...</td>\n",
       "      <td>18.529606</td>\n",
       "      <td>[-0.07874371428571428, -0.07750728571428571, 0...</td>\n",
       "      <td>[-0.00029004653, 0.0072122235, 0.0012765152, -...</td>\n",
       "      <td>[-0.033669516307554326, -0.1668532815387253, 0...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901</th>\n",
       "      <td>ham</td>\n",
       "      <td>Okie</td>\n",
       "      <td>okie</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0  okie   1  2.490739</td>\n",
       "      <td>2.490739</td>\n",
       "      <td>[-1.0514, -0.7125, -0.32979, -1.5782, -0.70277...</td>\n",
       "      <td>[0.0032638062, 0.000998768, -0.006656086, 0.00...</td>\n",
       "      <td>[-2.6187625668247585, -1.7746512543871416, -0....</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902</th>\n",
       "      <td>ham</td>\n",
       "      <td>That depends. How would you like to be treated...</td>\n",
       "      <td>depends would like treated</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0  depends   1  2.842...</td>\n",
       "      <td>9.400800</td>\n",
       "      <td>[0.5856725, -0.025622499999999993, -0.07667800...</td>\n",
       "      <td>[0.0071007977, 0.008866012, -0.006232733, 0.00...</td>\n",
       "      <td>[1.4380022035117963, -0.10766734072048496, -0....</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3903</th>\n",
       "      <td>ham</td>\n",
       "      <td>Right on brah, see you later</td>\n",
       "      <td>right brah see later</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0  right   1  1.806492\n",
       "...</td>\n",
       "      <td>8.250930</td>\n",
       "      <td>[0.41043999999999997, 0.8718945, 0.611363, -0....</td>\n",
       "      <td>[-0.0032308905, -0.0007188073, 0.0057696486, 0...</td>\n",
       "      <td>[1.1441046094744052, 2.590689262783445, 1.9755...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3904</th>\n",
       "      <td>ham</td>\n",
       "      <td>Waiting in e car 4 my mum lor. U leh? Reach ho...</td>\n",
       "      <td>waiting e car  mum lor u leh reach home already</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0  waiting   1  2.021...</td>\n",
       "      <td>18.849881</td>\n",
       "      <td>[0.3746515, 0.3813084, 0.7807202999999999, 0.0...</td>\n",
       "      <td>[-0.034012422, -0.061670527, 0.015993552, 0.06...</td>\n",
       "      <td>[0.7524747499755884, 0.7093350163164593, 1.480...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>nd time tried  contact u u â£ pound prize  cla...</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0            ...</td>\n",
       "      <td>29.685673</td>\n",
       "      <td>[-0.0032673076923077126, 0.2802763076923076, 0...</td>\n",
       "      <td>[0.04626287, -0.12486149, 0.010979156, 0.03321...</td>\n",
       "      <td>[-0.018272115681935517, 0.38059669250977396, 0...</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ã¼ b going to esplanade fr home?</td>\n",
       "      <td>ã¼ b going esplanade fr home</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0         ã¼   1  1...</td>\n",
       "      <td>12.328684</td>\n",
       "      <td>[0.2450002, 0.433446, -0.009058, -0.1098192, 0...</td>\n",
       "      <td>[-0.0032531489, -0.09509008, 0.011011036, 0.04...</td>\n",
       "      <td>[0.7474427145489011, 1.10828246067343, -0.1888...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity * mood soany suggestions</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0         pity   ...</td>\n",
       "      <td>15.080331</td>\n",
       "      <td>[-0.16283274999999997, 0.44291, -0.20726499999...</td>\n",
       "      <td>[0.15559773, -0.024660442, 0.09976124, 0.00577...</td>\n",
       "      <td>[-0.10259994304988762, 1.0048869796671016, -0....</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>guy bitching acted like i'd interested buying ...</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0          guy   ...</td>\n",
       "      <td>32.770129</td>\n",
       "      <td>[0.1625725923076923, -0.08889784615384616, 0.0...</td>\n",
       "      <td>[0.0029246681, -0.00042458618, 0.0025144704, -...</td>\n",
       "      <td>[0.4332410359621821, -0.43844977348643754, 0.1...</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl true name</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0  rofl   1  3.143951\n",
       "1 ...</td>\n",
       "      <td>7.558242</td>\n",
       "      <td>[0.264305, 0.7071000000000001, -0.36934, 0.107...</td>\n",
       "      <td>[0.0020055978, 0.006878876, -0.008461955, 0.00...</td>\n",
       "      <td>[0.5901408379733141, 1.5551135508332325, -0.80...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1672 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message  \\\n",
       "3900      ham  Ã mean it's confirmed... I tot they juz say o...   \n",
       "3901      ham                                               Okie   \n",
       "3902      ham  That depends. How would you like to be treated...   \n",
       "3903      ham                       Right on brah, see you later   \n",
       "3904      ham  Waiting in e car 4 my mum lor. U leh? Reach ho...   \n",
       "...       ...                                                ...   \n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568      ham              Will Ã¼ b going to esplanade fr home?   \n",
       "5569      ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570      ham  The guy did some bitching but I acted like i'd...   \n",
       "5571      ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                           stopsRemoved  \\\n",
       "3900               ã mean confirmed tot juz say oni ok   \n",
       "3901                                               okie   \n",
       "3902                        depends would like treated    \n",
       "3903                               right brah see later   \n",
       "3904    waiting e car  mum lor u leh reach home already   \n",
       "...                                                 ...   \n",
       "5567  nd time tried  contact u u â£ pound prize  cla...   \n",
       "5568                       ã¼ b going esplanade fr home   \n",
       "5569                      pity * mood soany suggestions   \n",
       "5570  guy bitching acted like i'd interested buying ...   \n",
       "5571                                     rofl true name   \n",
       "\n",
       "                                               tfMatrix   sumTFIDF  \\\n",
       "3900          word  tf    tf-idf\n",
       "0         ã   1  2...  18.529606   \n",
       "3901           word  tf    tf-idf\n",
       "0  okie   1  2.490739   2.490739   \n",
       "3902        word  tf    tf-idf\n",
       "0  depends   1  2.842...   9.400800   \n",
       "3903      word  tf    tf-idf\n",
       "0  right   1  1.806492\n",
       "...   8.250930   \n",
       "3904        word  tf    tf-idf\n",
       "0  waiting   1  2.021...  18.849881   \n",
       "...                                                 ...        ...   \n",
       "5567                word  tf    tf-idf\n",
       "0            ...  29.685673   \n",
       "5568          word  tf    tf-idf\n",
       "0         ã¼   1  1...  12.328684   \n",
       "5569            word  tf    tf-idf\n",
       "0         pity   ...  15.080331   \n",
       "5570            word  tf    tf-idf\n",
       "0          guy   ...  32.770129   \n",
       "5571     word  tf    tf-idf\n",
       "0  rofl   1  3.143951\n",
       "1 ...   7.558242   \n",
       "\n",
       "                                           glove-vector  \\\n",
       "3900  [-0.07874371428571428, -0.07750728571428571, 0...   \n",
       "3901  [-1.0514, -0.7125, -0.32979, -1.5782, -0.70277...   \n",
       "3902  [0.5856725, -0.025622499999999993, -0.07667800...   \n",
       "3903  [0.41043999999999997, 0.8718945, 0.611363, -0....   \n",
       "3904  [0.3746515, 0.3813084, 0.7807202999999999, 0.0...   \n",
       "...                                                 ...   \n",
       "5567  [-0.0032673076923077126, 0.2802763076923076, 0...   \n",
       "5568  [0.2450002, 0.433446, -0.009058, -0.1098192, 0...   \n",
       "5569  [-0.16283274999999997, 0.44291, -0.20726499999...   \n",
       "5570  [0.1625725923076923, -0.08889784615384616, 0.0...   \n",
       "5571  [0.264305, 0.7071000000000001, -0.36934, 0.107...   \n",
       "\n",
       "                                                doc2vec  \\\n",
       "3900  [-0.00029004653, 0.0072122235, 0.0012765152, -...   \n",
       "3901  [0.0032638062, 0.000998768, -0.006656086, 0.00...   \n",
       "3902  [0.0071007977, 0.008866012, -0.006232733, 0.00...   \n",
       "3903  [-0.0032308905, -0.0007188073, 0.0057696486, 0...   \n",
       "3904  [-0.034012422, -0.061670527, 0.015993552, 0.06...   \n",
       "...                                                 ...   \n",
       "5567  [0.04626287, -0.12486149, 0.010979156, 0.03321...   \n",
       "5568  [-0.0032531489, -0.09509008, 0.011011036, 0.04...   \n",
       "5569  [0.15559773, -0.024660442, 0.09976124, 0.00577...   \n",
       "5570  [0.0029246681, -0.00042458618, 0.0025144704, -...   \n",
       "5571  [0.0020055978, 0.006878876, -0.008461955, 0.00...   \n",
       "\n",
       "                                        vec_tfidf-glove cGroup_glove  \\\n",
       "3900  [-0.033669516307554326, -0.1668532815387253, 0...          ham   \n",
       "3901  [-2.6187625668247585, -1.7746512543871416, -0....         spam   \n",
       "3902  [1.4380022035117963, -0.10766734072048496, -0....          ham   \n",
       "3903  [1.1441046094744052, 2.590689262783445, 1.9755...          ham   \n",
       "3904  [0.7524747499755884, 0.7093350163164593, 1.480...          ham   \n",
       "...                                                 ...          ...   \n",
       "5567  [-0.018272115681935517, 0.38059669250977396, 0...          ham   \n",
       "5568  [0.7474427145489011, 1.10828246067343, -0.1888...          ham   \n",
       "5569  [-0.10259994304988762, 1.0048869796671016, -0....          ham   \n",
       "5570  [0.4332410359621821, -0.43844977348643754, 0.1...          ham   \n",
       "5571  [0.5901408379733141, 1.5551135508332325, -0.80...         spam   \n",
       "\n",
       "     cGroup_doc2vec cGroup_tfidf-glove  \n",
       "3900            ham               None  \n",
       "3901           spam               None  \n",
       "3902            ham               None  \n",
       "3903            ham               None  \n",
       "3904            ham               None  \n",
       "...             ...                ...  \n",
       "5567           spam               None  \n",
       "5568            ham               None  \n",
       "5569           spam               None  \n",
       "5570           spam               None  \n",
       "5571            ham               None  \n",
       "\n",
       "[1672 rows x 11 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdb.dataTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([ 0.00145649, -0.01432053,  0.01307351, -0.00200391, -0.00830727,\n",
       "        0.02941629, -0.00999487, -0.00073129, -0.00437657,  0.01471183,\n",
       "        0.00707789,  0.01578464,  0.00084015,  0.00189465, -0.00029905,\n",
       "        0.01071829,  0.00323365, -0.00443153, -0.01489976, -0.01932186,\n",
       "        0.01500085, -0.01300158,  0.00967808, -0.00938102, -0.01180961,\n",
       "        0.00983463, -0.00319925,  0.00618966, -0.00259511,  0.00234092,\n",
       "        0.00247946, -0.02748282,  0.00033443, -0.01787248,  0.00927453,\n",
       "       -0.01269134, -0.01494397, -0.01469267, -0.00249837, -0.00466744,\n",
       "        0.00638671, -0.00415108,  0.01221796, -0.01780416, -0.00916571,\n",
       "       -0.0219495 , -0.00583187,  0.02274373, -0.0055441 ,  0.00030472],\n",
       "      dtype=float32)], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdb.groupedCharacteristic['doc2vec'].loc['ham'].to_numpy(dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0514   -0.7125   -0.32979  -1.5782   -0.70277  -0.17696   0.35851\n",
      " -0.25738  -0.45986   0.69583  -0.59439  -0.071654  0.99636  -0.37387\n",
      "  0.55014  -0.55981   0.52405   0.58494   0.66762   0.84464  -0.27754\n",
      "  0.093692 -0.47661  -0.14204   0.56345   0.3176   -0.20212   0.38231\n",
      "  0.032153 -0.69724  -1.3483   -0.78941   0.20827   0.61859  -0.65964\n",
      "  0.050033 -0.021429 -1.4299    1.0405    0.42354  -0.79416   0.19858\n",
      "  0.047546  0.082816 -0.7052   -0.40723   0.39191   0.18906  -0.58996\n",
      " -0.033718] <class 'numpy.ndarray'>\n",
      "[array([ 0.00710858, -0.01191311,  0.01180887,  0.01427133, -0.00948243,\n",
      "        0.02567787, -0.01396888,  0.00585956, -0.02231221, -0.00297664,\n",
      "        0.01101326,  0.00572352,  0.00294924,  0.00215183, -0.00795537,\n",
      "        0.00165394,  0.00600958,  0.00063951, -0.01772013, -0.00849582,\n",
      "       -0.00011211, -0.00393122, -0.00595212, -0.00040865, -0.01173587,\n",
      "       -0.00106305, -0.01495443,  0.00643836, -0.00229097,  0.01362749,\n",
      "       -0.00711745, -0.01913031,  0.00014039, -0.01833201,  0.00807031,\n",
      "       -0.01243141, -0.02185382, -0.01512735, -0.02881254,  0.01520875,\n",
      "        0.00338098, -0.00104404, -0.00938869, -0.0114888 , -0.0065452 ,\n",
      "       -0.01630471,  0.0063195 ,  0.02020682,  0.00581036, -0.0086134 ],\n",
      "      dtype=float32)] <class 'numpy.ndarray'>\n",
      "[1.179057   0.82094306 1.179057   1.179057   0.820943   1.179057\n",
      " 0.820943   1.179057   0.82094306 0.82094306 1.179057   1.1790569\n",
      " 1.179057   1.179057   0.820943   1.179057   1.1790569  1.1790569\n",
      " 0.820943   0.820943   0.820943   0.820943   0.82094306 0.820943\n",
      " 0.82094306 0.820943   0.820943   1.179057   0.820943   1.179057\n",
      " 0.820943   0.820943   1.179057   0.820943   1.179057   0.82094306\n",
      " 0.820943   0.82094306 0.820943   1.179057   1.179057   0.82094306\n",
      " 0.820943   0.820943   0.82094306 0.820943   1.179057   1.179057\n",
      " 1.179057   0.820943  ]\n",
      "6.981272\n"
     ]
    }
   ],
   "source": [
    "a = fdb.dataTest['glove-vector'].iloc[1]\n",
    "b = fdb.groupedCharacteristic['doc2vec'].loc['ham'].to_numpy(dtype=object)\n",
    "print(a,type(a))\n",
    "print(b,type(b))\n",
    "import scipy\n",
    "print(scipy.spatial.distance.cosine(a,b))\n",
    "print(np.linalg.norm(scipy.spatial.distance.cosine(a,b)))\n",
    "#computedGroup = self.getNearestGroup(self.dataTest[vectorName].iloc[docId],vectorName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>stopsRemoved</th>\n",
       "      <th>tfMatrix</th>\n",
       "      <th>sumTFIDF</th>\n",
       "      <th>glove-vector</th>\n",
       "      <th>doc2vec</th>\n",
       "      <th>vec_tfidf-glove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0          go   1 ...</td>\n",
       "      <td>38.281443</td>\n",
       "      <td>[0.21390625000000005, 0.3857445625, -0.1334233...</td>\n",
       "      <td>[0.04005482, -0.06680761, 0.02545498, 0.024805...</td>\n",
       "      <td>[0.5959587370342363, 0.8768489600169621, -0.51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0      ok   1  1.31950...</td>\n",
       "      <td>12.583182</td>\n",
       "      <td>[-0.34427266666666667, -0.11794016666666667, 0...</td>\n",
       "      <td>[-0.014016584, -0.035048068, 0.011611654, 0.03...</td>\n",
       "      <td>[-0.6469232570438529, -0.4567087086249299, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry  wkly comp win fa cup final tkts st...</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0         entry ...</td>\n",
       "      <td>49.524838</td>\n",
       "      <td>[-0.3973114285714286, 0.43085399999999996, -0....</td>\n",
       "      <td>[0.0028259559, 0.0051632347, 0.0085555585, 0.0...</td>\n",
       "      <td>[-1.3248417366882783, 1.1032396880662387, -0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0        u   2  1.669...</td>\n",
       "      <td>16.431526</td>\n",
       "      <td>[0.17517428571428573, 0.24041571428571432, 0.2...</td>\n",
       "      <td>[-0.01914546, -0.09453999, 0.019697232, 0.0757...</td>\n",
       "      <td>[0.5123484443079068, 0.5753741094651186, 0.311...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think goes usf lives around though</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0     nah   1  2.70461...</td>\n",
       "      <td>16.678825</td>\n",
       "      <td>[0.19229857142857143, 0.4842861428571427, 0.19...</td>\n",
       "      <td>[-0.005010659, 0.00058875955, 0.0060600745, -0...</td>\n",
       "      <td>[0.47549546283727345, 1.2971284798171407, 0.48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>nd time tried  contact u u â£ pound prize  cla...</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0            ...</td>\n",
       "      <td>29.685673</td>\n",
       "      <td>[-0.0032673076923077126, 0.2802763076923076, 0...</td>\n",
       "      <td>[-0.012644604, -0.062778056, 0.013478121, 0.03...</td>\n",
       "      <td>[-0.018272115681935517, 0.38059669250977396, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ã¼ b going to esplanade fr home?</td>\n",
       "      <td>ã¼ b going esplanade fr home</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0         ã¼   1  1...</td>\n",
       "      <td>12.328684</td>\n",
       "      <td>[0.2450002, 0.433446, -0.009058, -0.1098192, 0...</td>\n",
       "      <td>[-0.023012374, -0.085845396, 0.046025265, 0.04...</td>\n",
       "      <td>[0.7474427145489011, 1.10828246067343, -0.1888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity * mood soany suggestions</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0         pity   ...</td>\n",
       "      <td>15.080331</td>\n",
       "      <td>[-0.16283274999999997, 0.44291, -0.20726499999...</td>\n",
       "      <td>[0.14092924, -0.011391963, 0.114448994, 0.1104...</td>\n",
       "      <td>[-0.10259994304988762, 1.0048869796671016, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>guy bitching acted like i'd interested buying ...</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0          guy   ...</td>\n",
       "      <td>32.770129</td>\n",
       "      <td>[0.1625725923076923, -0.08889784615384616, 0.0...</td>\n",
       "      <td>[0.0029246681, -0.00042458618, 0.0025144704, -...</td>\n",
       "      <td>[0.4332410359621821, -0.43844977348643754, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl true name</td>\n",
       "      <td>word  tf    tf-idf\n",
       "0  rofl   1  3.143951\n",
       "1 ...</td>\n",
       "      <td>7.558242</td>\n",
       "      <td>[0.264305, 0.7071000000000001, -0.36934, 0.107...</td>\n",
       "      <td>[0.0020055978, 0.006878876, -0.008461955, 0.00...</td>\n",
       "      <td>[0.5901408379733141, 1.5551135508332325, -0.80...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message  \\\n",
       "0         ham  Go until jurong point, crazy.. Available only ...   \n",
       "1         ham                      Ok lar... Joking wif u oni...   \n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3         ham  U dun say so early hor... U c already then say...   \n",
       "4         ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...       ...                                                ...   \n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568      ham              Will Ã¼ b going to esplanade fr home?   \n",
       "5569      ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570      ham  The guy did some bitching but I acted like i'd...   \n",
       "5571      ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                           stopsRemoved  \\\n",
       "0     go jurong point crazy available bugis n great ...   \n",
       "1                               ok lar joking wif u oni   \n",
       "2     free entry  wkly comp win fa cup final tkts st...   \n",
       "3                   u dun say early hor u c already say   \n",
       "4                nah think goes usf lives around though   \n",
       "...                                                 ...   \n",
       "5567  nd time tried  contact u u â£ pound prize  cla...   \n",
       "5568                       ã¼ b going esplanade fr home   \n",
       "5569                      pity * mood soany suggestions   \n",
       "5570  guy bitching acted like i'd interested buying ...   \n",
       "5571                                     rofl true name   \n",
       "\n",
       "                                               tfMatrix   sumTFIDF  \\\n",
       "0              word  tf    tf-idf\n",
       "0          go   1 ...  38.281443   \n",
       "1          word  tf    tf-idf\n",
       "0      ok   1  1.31950...  12.583182   \n",
       "2                word  tf    tf-idf\n",
       "0         entry ...  49.524838   \n",
       "3           word  tf    tf-idf\n",
       "0        u   2  1.669...  16.431526   \n",
       "4          word  tf    tf-idf\n",
       "0     nah   1  2.70461...  16.678825   \n",
       "...                                                 ...        ...   \n",
       "5567                word  tf    tf-idf\n",
       "0            ...  29.685673   \n",
       "5568          word  tf    tf-idf\n",
       "0         ã¼   1  1...  12.328684   \n",
       "5569            word  tf    tf-idf\n",
       "0         pity   ...  15.080331   \n",
       "5570            word  tf    tf-idf\n",
       "0          guy   ...  32.770129   \n",
       "5571     word  tf    tf-idf\n",
       "0  rofl   1  3.143951\n",
       "1 ...   7.558242   \n",
       "\n",
       "                                           glove-vector  \\\n",
       "0     [0.21390625000000005, 0.3857445625, -0.1334233...   \n",
       "1     [-0.34427266666666667, -0.11794016666666667, 0...   \n",
       "2     [-0.3973114285714286, 0.43085399999999996, -0....   \n",
       "3     [0.17517428571428573, 0.24041571428571432, 0.2...   \n",
       "4     [0.19229857142857143, 0.4842861428571427, 0.19...   \n",
       "...                                                 ...   \n",
       "5567  [-0.0032673076923077126, 0.2802763076923076, 0...   \n",
       "5568  [0.2450002, 0.433446, -0.009058, -0.1098192, 0...   \n",
       "5569  [-0.16283274999999997, 0.44291, -0.20726499999...   \n",
       "5570  [0.1625725923076923, -0.08889784615384616, 0.0...   \n",
       "5571  [0.264305, 0.7071000000000001, -0.36934, 0.107...   \n",
       "\n",
       "                                                doc2vec  \\\n",
       "0     [0.04005482, -0.06680761, 0.02545498, 0.024805...   \n",
       "1     [-0.014016584, -0.035048068, 0.011611654, 0.03...   \n",
       "2     [0.0028259559, 0.0051632347, 0.0085555585, 0.0...   \n",
       "3     [-0.01914546, -0.09453999, 0.019697232, 0.0757...   \n",
       "4     [-0.005010659, 0.00058875955, 0.0060600745, -0...   \n",
       "...                                                 ...   \n",
       "5567  [-0.012644604, -0.062778056, 0.013478121, 0.03...   \n",
       "5568  [-0.023012374, -0.085845396, 0.046025265, 0.04...   \n",
       "5569  [0.14092924, -0.011391963, 0.114448994, 0.1104...   \n",
       "5570  [0.0029246681, -0.00042458618, 0.0025144704, -...   \n",
       "5571  [0.0020055978, 0.006878876, -0.008461955, 0.00...   \n",
       "\n",
       "                                        vec_tfidf-glove  \n",
       "0     [0.5959587370342363, 0.8768489600169621, -0.51...  \n",
       "1     [-0.6469232570438529, -0.4567087086249299, -0....  \n",
       "2     [-1.3248417366882783, 1.1032396880662387, -0.5...  \n",
       "3     [0.5123484443079068, 0.5753741094651186, 0.311...  \n",
       "4     [0.47549546283727345, 1.2971284798171407, 0.48...  \n",
       "...                                                 ...  \n",
       "5567  [-0.018272115681935517, 0.38059669250977396, 0...  \n",
       "5568  [0.7474427145489011, 1.10828246067343, -0.1888...  \n",
       "5569  [-0.10259994304988762, 1.0048869796671016, -0....  \n",
       "5570  [0.4332410359621821, -0.43844977348643754, 0.1...  \n",
       "5571  [0.5901408379733141, 1.5551135508332325, -0.80...  \n",
       "\n",
       "[5572 rows x 8 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdb.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
